{
    "version": "https://jsonfeed.org/version/1",
    "title": "kherashanu.com",
    "description": "",
    "home_page_url": "https://kherashanu.com",
    "feed_url": "https://kherashanu.com/feed.json",
    "user_comment": "",
    "author": {
        "name": "khera shanu"
    },
    "items": [
        {
            "id": "https://kherashanu.com/pyspark-for-everyone-part-1-big-data-history-and-concepts-wip.html",
            "url": "https://kherashanu.com/pyspark-for-everyone-part-1-big-data-history-and-concepts-wip.html",
            "title": "PySpark for Everyone - Part 1: Big Data - History and Concepts [WIP]",
            "summary": "Last time, you got to know me â€“ your friendly neighborhood data&hellip;",
            "content_html": "<p><a href=\"https://kherashanu.com/pyspark-for-everyone-part-0-why-me.html\" target=\"_blank\" rel=\"noopener noreferrer\">Last time</a>, you got to know me â€“ your friendly neighborhood data wrangler. Today, we're diving into the wild world of Big Data. Get ready for a rollercoaster ride through history, sprinkled with some tech talk and a dash of humour.</p>\n<p>Let's get this party started! ðŸ¥³</p>\n<h3>The Evolution of Big Data</h3>\n<p class=\"mb-2 last:mb-0\">Big Data didn't just wake up one day and say, \"Hey, I'm here to blow your mind!\" No, it took its sweet time. Here's a quick rundown:</p>\n<ul>\n<li><strong>1970s-1980s</strong>: Think of this era as the Stone Age of data. Relational databases and data warehouses were the hot new thing. People were just starting to realize that data could be more than just numbers on a page.</li>\n<li><strong>1990s</strong>: The World Wide Web arrived, and suddenly, data was everywhere. It was like someone opened Pandora's box and out came a flood of information.</li>\n<li><strong>2000s</strong>: Web 2.0, social media, and IoT devices turned the data faucet on full blast. The amount of data being generated was enough to make your head spin.</li>\n<li><strong>2010s</strong>: Cloud computing and big data technologies became the new norm. Companies started swimming in data like Scrooge McDuck in his money bin.</li>\n</ul>\n<hr>\n<figure ><figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://kherashanu.com/media/posts/2/vvv_band_standard-3.png\" alt=\"The VVV Band\" width=\"512\" height=\"512\" sizes=\"(max-width: 1024px) 100vw, 1024px\" srcset=\"https://kherashanu.com/media/posts/2/responsive/vvv_band_standard-3-xs.webp 300w ,https://kherashanu.com/media/posts/2/responsive/vvv_band_standard-3-sm.webp 480w ,https://kherashanu.com/media/posts/2/responsive/vvv_band_standard-3-md.webp 768w ,https://kherashanu.com/media/posts/2/responsive/vvv_band_standard-3-lg.webp 1024w\"></figure>\n<figcaption ><strong>V V V</strong></figcaption>\n</figure>\n<p>Â </p>\n<h3>Defining Big Data: The Three V's</h3>\n<p class=\"mb-2 last:mb-0\">Big Data is often summed up by the \"Three V's.\" No, it's not a new boy band. Here's what it means:</p>\n<ol>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>Volume</strong>: We're talking about a ridiculous amount of data. Facebook processes over 500 terabytes of data daily. That's a lot of cat videos and baby pictures, folks!</p>\n</li>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>Velocity</strong>: This is the speed at which new data is generated. Twitter handles around 500 million tweets per day. That's enough to make your head spin faster than a hamster on a wheel.</p>\n</li>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>Variety</strong>: Data comes in all shapes and sizes. You've got structured data (like databases), semi-structured data (JSON, XML), and unstructured data (text, images, videos). It's like a digital potluck â€“ you never know what you're going to get.</p>\n</li>\n</ol>\n<figure ><figure class=\"post__image post__image--wide\"><img loading=\"lazy\"  src=\"https://upload.wikimedia.org/wikipedia/commons/e/ee/Big_Data.png\" width=\"702\" height=\"484\" data-is-external-image=\"true\"></figure>\n<figcaption >Volume, Variety and Velocity. Source: Wikipedia</figcaption>\n</figure>\n<hr>\n<h3>Key Concepts in Big Data</h3>\n<p class=\"mb-2 last:mb-0\">Now, let's talk about some core ideas that make Big Data tick. Think of these as the secret ingredients in Grandma's famous cookie recipe:</p>\n<ul>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>Distributed Computing</strong>: This is all about spreading the workload across multiple machines. It's like having a bunch of elves working together to build a data wonderland.</p>\n</li>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>Scalability</strong>: The ability to scale up (or down) your computing resources based on demand. It's like having an elastic waistband on your favorite pair of pants â€“ it expands when you need it.</p>\n</li>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>Fault Tolerance</strong>: Ensuring that your system keeps running smoothly even if some parts fail. It's like having a backup plan for your backup plan. Because, you know, Murphy's Law.</p>\n</li>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>Data Lake</strong>: A centralized repository where you can dump all your structured and unstructured data. It's like a giant digital junk drawer. You know, the one where you keep everything from old batteries to that one sock that lost its mate.</p>\n</li>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>ETL (Extract, Transform, Load)</strong>: This is the process of gathering data from various sources, transforming it into something useful, and loading it into a target system. It's the data equivalent of turning raw ingredients into a gourmet meal. Bon appÃ©tit!</p>\n</li>\n</ul>\n<figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://i.pinimg.com/originals/30/fa/f1/30faf1f0732bec0c7bf4e911ecd364f5.gif\" alt=\"Salt Sprinkle GIF - Salt Sprinkle Chef - Discover &amp; Share GIFs\" width=\"371\" height=\"373\" data-is-external-image=\"true\"></figure>\n<p>Â </p>\n<hr>\n<h3>Challenges in Big Data</h3>\n<p class=\"mb-2 last:mb-0\">Alright, it's not all rainbows and unicorns. Big Data comes with its own set of challenges. Think of these as the plot twists in your favourite TV show:</p>\n<ul>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>Data Quality</strong>: Ensuring your data is accurate, complete, and consistent. Because, let's face it, garbage in, garbage out.</p>\n</li>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>Privacy and Security</strong>: Protecting sensitive information and complying with data regulations. No one wants their personal data floating around unsecured. It's like leaving your front door wide open â€“ not a good idea.</p>\n</li>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>Skill Gap</strong>: Finding people with the right expertise to work with Big Data technologies. It's like trying to find a needle in a haystack. Or a Wi-Fi signal at a music festival.</p>\n</li>\n<li>\n<p class=\"mb-2 last:mb-0\"><strong>Technology Selection</strong>: Choosing the right tools and frameworks from a vast ecosystem. It's like being a kid in a candy store â€“ so many options, but which ones are the best?</p>\n</li>\n</ul>\n<hr>\n<h3><figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://media.tenor.com/WX-l3Ai6BNsAAAAM/the-end-the-end-is-near.gif\" alt=\"End Is Near GIFs | Tenor\" width=\"366\" height=\"276\" data-is-external-image=\"true\"></figure></h3>\n<h3>The Impact of Big Data</h3>\n<p class=\"mb-2 last:mb-0\">Big Data is a game-changer across various industries. It's like the Swiss Army knife of the tech world:</p>\n<ul>\n<li><strong>Healthcare</strong>: Predictive analytics for disease outbreaks, personalized medicine â€“ it's revolutionising patient care. Dr. Data to the rescue!</li>\n<li><strong>Finance</strong>: Fraud detection, risk assessment, algorithmic trading â€“ Big Data is making the financial world smarter and safer. Cha-ching!</li>\n<li><strong>Retail</strong>: Customer behaviour analysis, inventory optimisation â€“ it's helping retailers understand their customers better and stock smarter. Shop till you drop!</li>\n<li><strong>Transportation</strong>: Route optimization, predictive maintenance â€“ Big Data is making travel more efficient and reliable. All aboard the data express!</li>\n</ul>",
            "image": "https://kherashanu.com/media/posts/2/big_data_standard.png",
            "author": {
                "name": "khera shanu"
            },
            "tags": [
                   "PySpark",
                   "Data Engineering",
                   "Apache Spark"
            ],
            "date_published": "2024-02-06T04:03:00+05:30",
            "date_modified": "2024-08-12T00:02:25+05:30"
        },
        {
            "id": "https://kherashanu.com/pyspark-for-everyone-part-0-why-me.html",
            "url": "https://kherashanu.com/pyspark-for-everyone-part-0-why-me.html",
            "title": "PySpark for Everyone - Part 0: Why Me?",
            "summary": "Before diving into the world of big data and PySpark, let me&hellip;",
            "content_html": "\n  <p>\n    Before diving into the world of big data and PySpark, let me introduce myself and explain why I believe I can guide you through these concepts effectively.<br><br>For nearly a decade, I worked primarily as a backend developer. Although I dabbled in various other roles, backend development always felt like my true calling. Interestingly, I began working with data engineering tasks before I even knew the term existed. My official transition to data engineering occurred while I was a Senior Software Engineer at a Silicon Valley company called Nextroll.<br><br>Our team at Nextroll had minimal \"typical\" backend work. We mostly fixed each other's bugs or added minor features. However, a sudden influx of data engineering tasks led our entire backend team to shift focus. For over a year, I performed data engineering duties without holding the official title.<br><br>Backend engineering started to feel monotonous to me. While scaling a product for a billion users in a cost-effective and resilient manner is undoubtedly cool and challenging, such opportunities are rare. I realized that data and AI represent the future. Data engineering seemed like the perfect avenue to combine my passion for backend development with a role more resilient to future changes. I am optimistic about AI's potential in the next decade, and I believe backend roles may become more specialized and automated. In contrast, data engineering is a field where ten different people might give you ten different definitions.\n  </p>\n\n  <p>\n    Nextroll faced tough times due to the deprecation of third-party cookies in Chrome, which led to many layoffs, including mine. I saw this as the perfect opportunity to officially switch to a data engineering role. Currently, I work remotely for a company that allows me to support BP (British Petroleum). Remote work is crucial for me.<br><br><b>Why am I, a relatively new data engineer, the right person to guide you?</b><br><br>I bring a unique perspective. Having worked in various environments and roles, I can view data engineering from a broader angle that many seasoned data engineers might not. I consider myself a competent programmer with a solid understanding of fundamental computer science principles and Python.<br><br>I know self-promotion can be off-putting, but it's essential for you to trust me as we embark on this journey together. <em>Shall we begin?</em>\n  </p>",
            "image": "https://kherashanu.com/media/posts/1/pyspark_post_1_standard.png",
            "author": {
                "name": "khera shanu"
            },
            "tags": [
                   "PySpark",
                   "Data Engineering",
                   "Apache Spark"
            ],
            "date_published": "2024-02-02T22:10:00+05:30",
            "date_modified": "2024-08-11T22:26:11+05:30"
        }
    ]
}
